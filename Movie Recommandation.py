# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JgwKCK7GJ7eFx4GIqYNJfFnnTf6IUTe4
"""

import pandas as pd
import numpy as np
from scipy.spatial.distance import cosine # For calculating cosine similarity
import os
import zipfile
import requests


# --- Configuration for MovieLens Dataset ---
# IMPORTANT: Make sure 'ratings.csv' and 'movies.csv' are in the same directory as this script.
RATINGS_FILE = 'ratings.csv'
MOVIES_FILE = 'movies.csv'
DATASET_URL = 'https://files.grouplens.org/datasets/movielens/ml-latest-small.zip'
DATASET_DIR = 'ml-latest-small'
ZIP_FILE_NAME = 'ml-latest-small.zip'

# --- 1. Data Preparation: Load MovieLens Dataset ---
print("--- 1. Loading MovieLens Dataset ---")

# Download and extract the dataset if not already present
if not os.path.exists(DATASET_DIR):
    print(f"Dataset directory '{DATASET_DIR}' not found. Downloading and extracting...")
    try:
        # Download the zip file
        response = requests.get(DATASET_URL, stream=True)
        response.raise_for_status() # Raise an exception for bad status codes
        with open(ZIP_FILE_NAME, 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192):
                f.write(chunk)

        # Extract the zip file
        with zipfile.ZipFile(ZIP_FILE_NAME, 'r') as zip_ref:
            zip_ref.extractall('.') # Extract to the current directory

        # Rename the extracted directory if it's different from DATASET_DIR
        # (Sometimes the extracted folder is named differently, e.g., ml-latest-small)
        extracted_folder_name = zip_ref.namelist()[0].split('/')[0]
        if extracted_folder_name != DATASET_DIR:
            os.rename(extracted_folder_name, DATASET_DIR)


        print("Dataset downloaded and extracted successfully.")

    except Exception as e:
        print(f"An error occurred during dataset download or extraction: {e}")
        # Exit gracefully if data is not available
        exit()

# Now load the files from the extracted directory
try:
    # Construct full paths to the CSV files within the dataset directory
    ratings_file_path = os.path.join(DATASET_DIR, RATINGS_FILE)
    movies_file_path = os.path.join(DATASET_DIR, MOVIES_FILE)

    # Load ratings data (userId, movieId, rating, timestamp)
    ratings_df = pd.read_csv(ratings_file_path)
    # Load movies data (movieId, title, genres)
    movies_df = pd.read_csv(movies_file_path)

    print("Ratings Data Head:")
    display(ratings_df.head())
    print("\nMovies Data Head:")
    display(movies_df.head())

    # Merge ratings with movie titles
    # We'll use 'title' from movies_df instead of 'movieId' for readability in the matrix
    df = pd.merge(ratings_df, movies_df, on='movieId')

    print("\nMerged Data Head (ratings + movie titles):")
    display(df.head())
    print(f"Total merged data points: {len(df)}")

    # Create the User-Item Matrix
    # Rows are users, columns are movie titles, values are ratings.
    # Unrated movies will automatically be NaN (Not a Number)
    user_movie_matrix = df.pivot_table(index='userId', columns='title', values='rating')

    print("\n--- User-Movie Rating Matrix (Partial View) ---")
    print("This matrix shows how users have rated movies. NaN means unrated:")
    # Displaying a small part as it can be very wide
    display(user_movie_matrix.iloc[:5, :10]) # First 5 users, first 10 movies
    print(f"Matrix shape (Users x Movies): {user_movie_matrix.shape}")

except FileNotFoundError:
    print(f"Error: Make sure '{RATINGS_FILE}' and '{MOVIES_FILE}' are in the correct location within the '{DATASET_DIR}' directory.")
    # This should not happen if the download and extraction were successful, but good to have a fallback.
    exit()
except Exception as e:
    print(f"An error occurred during data loading: {e}")
    exit()

# --- 2. Calculate User Similarity (Cosine Similarity) ---

def calculate_user_similarity(matrix):
    """
    Calculates the cosine similarity between all pairs of users.
    Handles NaN values by only considering commonly rated items.
    """
    # Use fillna(0) for cosine similarity calculation if NaNs are present,
    # but filter for common rated items.
    # Alternatively, use a pairwise similarity function that handles NaNs directly.
    # For a robust solution, libraries like scikit-learn's pairwise_distances
    # or the Surprise library are better.
    # Here, we'll manually handle NaN for common items as a demonstration.

    num_users = matrix.shape[0]
    similarity_matrix = pd.DataFrame(np.zeros((num_users, num_users)),
                                     index=matrix.index, columns=matrix.index)

    # It's more efficient to iterate through the matrix once for dot products
    # and norms, especially for sparse data. However, for demonstration
    # with NaN handling on common items, the explicit loop is shown.
    # For performance, consider using sklearn.metrics.pairwise.cosine_similarity
    # after handling NaNs appropriately (e.g., filling with 0 and masking).

    for i in range(num_users):
        user1_id = matrix.index[i]
        for j in range(i, num_users): # Iterate only upper triangle for efficiency
            user2_id = matrix.index[j]

            if user1_id == user2_id:
                similarity_matrix.loc[user1_id, user2_id] = 1.0
            else:
                # Get ratings for movies rated by user1
                user1_ratings = matrix.loc[user1_id].dropna()
                # Get ratings for movies rated by user2
                user2_ratings = matrix.loc[user2_id].dropna()

                # Find common movies rated by both users
                common_movies = user1_ratings.index.intersection(user2_ratings.index)

                if len(common_movies) == 0:
                    similarity = 0.0
                else:
                    # Extract ratings for common movies
                    v1 = user1_ratings.loc[common_movies].values
                    v2 = user2_ratings.loc[common_movies].values

                    # Ensure vectors are not all zeros for cosine similarity
                    # A dot product of zero vectors is 0, norm of zero vectors is 0.
                    # Cosine similarity is undefined for zero vectors.
                    # Treat similarity as 0 if either vector is all zeros for common items.
                    if np.sum(v1**2) == 0 or np.sum(v2**2) == 0:
                         similarity = 0.0
                    else:
                        # Calculate cosine similarity
                        dot_product = np.dot(v1, v2)
                        norm_v1 = np.linalg.norm(v1)
                        norm_v2 = np.linalg.norm(v2)
                        similarity = dot_product / (norm_v1 * norm_v2)

                similarity_matrix.loc[user1_id, user2_id] = similarity
                similarity_matrix.loc[user2_id, user1_id] = similarity # Symmetric matrix

    return similarity_matrix

print("\n--- 2. Calculating User Similarity (This may take a moment for larger datasets) ---")
user_similarity_matrix = calculate_user_similarity(user_movie_matrix)

print("\n--- User Similarity Matrix (Partial View) ---")
print("This matrix shows how similar each user is to every other user:")
display(user_similarity_matrix.iloc[:5, :5]) # First 5x5 users

# --- 3. Generate Recommendations for a Target User ---

def recommend_movies(target_user_id, user_movie_matrix, user_similarity_matrix, num_recommendations=5, min_common_ratings=2):
    """
    Recommends movies to a target user based on user-based collaborative filtering.
    Filters out movies already rated by the target user.
    Uses a weighted average of ratings from similar users.
    """
    print(f"\n--- 3. Generating Recommendations for User {target_user_id} ---")

    if target_user_id not in user_movie_matrix.index:
        print(f"Error: User {target_user_id} not found in the dataset.")
        return {}

    # Get the target user's ratings
    target_user_ratings = user_movie_matrix.loc[target_user_id]

    # Identify movies the target user has NOT yet rated (where value is NaN)
    unrated_movies = target_user_ratings[target_user_ratings.isna()].index.tolist()

    if not unrated_movies:
        print(f"User {target_user_id} has rated all available movies or there are no unrated movies to recommend.")
        return {}

    # Get similarities of the target user with all other users
    # Exclude self-similarity and sort by similarity in descending order
    similar_users = user_similarity_matrix.loc[target_user_id].sort_values(ascending=False)
    similar_users = similar_users.drop(target_user_id) # Remove target user themselves

    predicted_ratings = {}

    for movie_title in unrated_movies:
        weighted_sum = 0
        similarity_sum = 0

        # Collect ratings for the current movie from similar users
        relevant_similar_users = []
        for sim_user_id, sim_score in similar_users.items():
            # Only consider users who have rated this movie and have a positive similarity score
            if not pd.isna(user_movie_matrix.loc[sim_user_id, movie_title]) and sim_score > 0:
                relevant_similar_users.append((sim_user_id, sim_score))

        if len(relevant_similar_users) < min_common_ratings:
            # Skip if not enough similar users rated this movie
            predicted_ratings[movie_title] = 0.0 # Assign 0 if not enough data
            continue

        # Calculate weighted sum for prediction
        for sim_user_id, sim_score in relevant_similar_users:
            rating_by_sim_user = user_movie_matrix.loc[sim_user_id, movie_title]
            weighted_sum += sim_score * rating_by_sim_user
            similarity_sum += sim_score

        # Calculate predicted rating
        if similarity_sum > 0:
            predicted_ratings[movie_title] = weighted_sum / similarity_sum
        else:
            predicted_ratings[movie_title] = 0.0 # Should not happen if relevant_similar_users is non-empty

    # Convert to Series, sort, and filter out movies with no prediction (0.0)
    recommended_movies = pd.Series(predicted_ratings).sort_values(ascending=False)
    recommended_movies = recommended_movies[recommended_movies > 0.0]

    if recommended_movies.empty:
        print(f"No strong recommendations found for User {target_user_id} based on similar users.")
        return {}

    print(f"Top {num_recommendations} recommendations for User {target_user_id}:")
    # Get original movie titles to display
    final_recommendations = recommended_movies.head(num_recommendations)
    for movie, rating in final_recommendations.items():
        print(f"- {movie} (Predicted Rating: {rating:.2f})")

    return final_recommendations.to_dict()

# --- Example Usage with real MovieLens User IDs ---
# You can pick any userId from the ratings.csv file, e.g., userId 1, 2, 3...
# User IDs in ml-latest-small typically range from 1 to 610.

# Let's try to get recommendations for a few different users.
# You might need to adjust the user_id if your dataset is different or if the user
# has rated all movies or has no similar users who rated unrated movies.

# Example 1: Recommend for User 1
recommendations_user1 = recommend_movies(1, user_movie_matrix, user_similarity_matrix, num_recommendations=5)

# Example 2: Recommend for User 2 (if exists and has unrated movies)
recommendations_user2 = recommend_movies(2, user_movie_matrix, user_similarity_matrix, num_recommendations=5)

# Example 3: Recommend for a user that might not have many unrated movies
recommendations_user_custom = recommend_movies(600, user_movie_matrix, user_similarity_matrix, num_recommendations=5)

print("\n--- Recommendation System Execution Complete ---")
print("Consider trying other users or increasing 'num_recommendations' and 'min_common_ratings'.")
print("For more advanced systems, explore Item-Based CF or Matrix Factorization (e.g., with Surprise library).")